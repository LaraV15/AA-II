{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R17_gCYEpUj6"
      },
      "source": [
        "# Lab 9 - Clasificacion de Artículos con RNNs\n",
        "\n",
        "El objetivo de este laboratorio es entrenar un clasificador de noticias utilizando una red neuronal recurrente (RNN). Para ello, se utilizará el un subset de TensorFlow del dataset AG, que contiene 120,000 noticias clasificadas como World, Sports, Business o Sci/Tech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDnpx1sopUj9"
      },
      "source": [
        "## Preparación del entorno.\n",
        "\n",
        "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkzRyzPrpUj-",
        "outputId": "0f011fd1-4e99-4062-9a8f-9d80f864aa23"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"lab9\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
        "  os.chdir(REPO_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWRXk_wfpUj-"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-0gu4nNpUj_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJT506AXpUj_"
      },
      "source": [
        "Establecer GPU por defecto en caso de estar disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMPBKDUqpUkA",
        "outputId": "628c8777-41dd-42c8-aee2-b981574d53f9"
      },
      "outputs": [],
      "source": [
        "# Configurar para que TensorFlow utilice la GPU por defecto\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        # Especificar la GPU por defecto\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Manejar error\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFivZvwrr3c"
      },
      "source": [
        "Cargar dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4SEGiicron5",
        "outputId": "5536eb9b-2680-4b70-af81-a3d12224fa64"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load('ag_news_subset', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t2GvwFlsDxB"
      },
      "source": [
        "Inspeccionar dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYKVTIssDxC",
        "outputId": "8ab86baa-f409-456b-8524-5b747c7a9e1c"
      },
      "outputs": [],
      "source": [
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJrSBs93n_w"
      },
      "source": [
        "Vemos que el primer elemento es un tf.string, que contiene la reseña de la película. El segundo elemento es un tf.int64, que contiene la etiqueta de la reseña (0 para negativa, 1 para positiva).\n",
        "\n",
        "Inspeccionamos algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "6qEllzoh3n_y",
        "outputId": "76625eb0-e3d3-4fd4-b373-a9d015b0d00a"
      },
      "outputs": [],
      "source": [
        "LABELS = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', LABELS[label.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc6bR40slUd"
      },
      "source": [
        "Shuffle y batching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP7JcxqnslUk"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostrar un batch de ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizar el análisis exploratorio necesario para determinar la distribución de las clases, longitud de los artículos, frecuencia de palabras, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### COMPLETAR CON ANÁLISIS EXPLORATORIO DE LOS DATOS ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un tokenizador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 10000 # Reemplazar con el tamaño del vocabulario deseado\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "\n",
        "only_text = train_dataset.map(lambda text, label: text)\n",
        "\n",
        "# La función adapt ajusta el vocabulario al texto, debe ser llamada con un dataset de texto\n",
        "encoder.adapt(only_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostramos los primeros 20 tokens:\n",
        "\n",
        "Los dos primeros tokens son los de padding y desconocido, respectivamente. Los siguientes tokens son los más comunes en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez que tenemos el tokenizador, podemos convertir las reseñas a tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_example = encoder(example)[0].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construimos el siguiente modelo:\n",
        "\n",
        "![model.png](model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compilamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos una función para plotear métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluamos métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Corremos sobre artículos de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podemos tomar descripciones artículos de la web y clasificarlos con el modelo entrenado (o generar artículos propios)\n",
        "\n",
        "example = [\"The national team won the championship game by a score of 3-1.\"]\n",
        "predictions = model.predict(example)\n",
        "print(example, LABELS[np.argmax(predictions[0])])\n",
        "\n",
        "example = [\"A new start was discovered by the Hubble Space Telescope\"]\n",
        "predictions = model.predict(example)\n",
        "print(example, LABELS[np.argmax(predictions[0])])\n",
        "\n",
        "example = [\"GameStop stock gains nearly 60% as meme-stock market returns with a vengeance\"]\n",
        "predictions = model.predict(example)\n",
        "print(example, LABELS[np.argmax(predictions[0])])\n",
        "\n",
        "example = [\"Xi’s visit to Hungary and Serbia brings new Chinese investment and deeper ties to Europe’s doorstep\"]\n",
        "predictions = model.predict(example)\n",
        "print(example, LABELS[np.argmax(predictions[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probar con distintas arquitecturas de red, tamaño de diccionario y tamaño de embeddings."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
