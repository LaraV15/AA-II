{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R17_gCYEpUj6"
      },
      "source": [
        "# Lab 9 - Sentiment Analysis con RNNs\n",
        "\n",
        "El objetivo de este laboratorio es entrenar un clasificador de reseñas de películas utilizando una red neuronal recurrente (RNN). Para ello, se utilizará el dataset de IMDB, que contiene 50,000 reseñas de películas etiquetadas como positivas o negativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDnpx1sopUj9"
      },
      "source": [
        "## Preparación del entorno.\n",
        "\n",
        "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkzRyzPrpUj-",
        "outputId": "0f011fd1-4e99-4062-9a8f-9d80f864aa23"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"lab9\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
        "  os.chdir(REPO_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWRXk_wfpUj-"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-0gu4nNpUj_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJT506AXpUj_"
      },
      "source": [
        "Establecer GPU por defecto en caso de estar disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMPBKDUqpUkA",
        "outputId": "628c8777-41dd-42c8-aee2-b981574d53f9"
      },
      "outputs": [],
      "source": [
        "# Configurar para que TensorFlow utilice la GPU por defecto\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        # Especificar la GPU por defecto\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Manejar error\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFivZvwrr3c"
      },
      "source": [
        "Cargar dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4SEGiicron5",
        "outputId": "5536eb9b-2680-4b70-af81-a3d12224fa64"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t2GvwFlsDxB"
      },
      "source": [
        "Inspeccionar dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYKVTIssDxC",
        "outputId": "8ab86baa-f409-456b-8524-5b747c7a9e1c"
      },
      "outputs": [],
      "source": [
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJrSBs93n_w"
      },
      "source": [
        "Vemos que el primer elemento es un tf.string, que contiene la reseña de la película. El segundo elemento es un tf.int64, que contiene la etiqueta de la reseña (0 para negativa, 1 para positiva).\n",
        "\n",
        "Inspeccionamos algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "6qEllzoh3n_y",
        "outputId": "76625eb0-e3d3-4fd4-b373-a9d015b0d00a"
      },
      "outputs": [],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc6bR40slUd"
      },
      "source": [
        "Shuffle y batching:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP7JcxqnslUk"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostrar un batch de ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos un tokenizador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "\n",
        "only_text = train_dataset.map(lambda text, label: text)\n",
        "\n",
        "# La función adapt ajusta el vocabulario al texto, debe ser llamada con un dataset de texto\n",
        "encoder.adapt(only_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mostramos los primeros 20 tokens:\n",
        "\n",
        "Los dos primeros tokens son los de padding y desconocido, respectivamente. Los siguientes tokens son los más comunes en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez que tenemos el tokenizador, podemos convertir las reseñas a tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_example = encoder(example)[0].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construimos el siguiente modelo:\n",
        "\n",
        "![model.png](model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compilamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos una función para plotear métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluamos métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Corremos sobre reseñas de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "\n",
        "print(sample_text)\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('An awful movie. A lackluster plot, uninspired performances, and forgettable action sequences.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "\n",
        "print(sample_text)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probar agregando una segunda capa LSTM bidireccional, la primer capa debe devolver secuencias (argumento `return_sequences=True`)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
