{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Laboratorio 10 A - Generacion de texto con RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwpJ5IffzRG6"
   },
   "source": [
    "Este laboratorio demuestra cómo generar texto usando una character-based RNN. Trabajará con un conjunto de datos de los escritos de Game Of Thrones. Dada una secuencia de caracteres a partir de estos datos, se entrena un modelo para predecir el siguiente carácter de la secuencia. Se pueden generar secuencias de texto más largas llamando al modelo repetidamente.\n",
    "El siguiente es el resultado de muestra cuando el modelo de este tutorial se entrenó durante 30 épocas y comenzó con el mensaje \"The Targaryens\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcygKkEVZBaa"
   },
   "source": [
    "<pre>\n",
    "The Targaryens and the other lefts had shared a bench. He may even let them get a grimmer if you storm under the stables. \n",
    "\n",
    "We'll want to her when she'd leave the toscat, Grand Maester Pycelle told him. It meant the lord Freth put us his shoulder, and the ilinit is a primate foolide as beft by a babe as well. Yet Jon Arryn's meat was fled, Arya could taste it. Then he finished faintly in her need, but massive resumed he was needed to below. And so Dany came up, offry frightened him.  I am sorry, my princess. The whores are brought by the traitor. \n",
    "\n",
    "There was a stout man in long and hard.\n",
    "\n",
    "Robb lifted his shoulders with his back whise arm and skirts and moonbalat, amession behind him, quick as a snake of bone and spit. Catelyn knelt beside her, Sansa had eyes shownered in Arya rushing toward him and heard the soft cross and spinned deep beet away and ran in half, defiant.  How long do I do?  he asked her.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno.\n",
    "\n",
    "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_NAME = \"lab10\"\n",
    "if REPO_NAME not in os.getcwd():\n",
    "  if not os.path.exists(REPO_NAME):\n",
    "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
    "  os.chdir(REPO_NAME)\n",
    "\n",
    "# Install tensorflow 2.15\n",
    "!pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:51.777470Z",
     "iopub.status.busy": "2023-11-16T12:28:51.777245Z",
     "iopub.status.idle": "2023-11-16T12:28:54.138340Z",
     "shell.execute_reply": "2023-11-16T12:28:54.137637Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecer GPU por defecto en caso de estar disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar para que TensorFlow utilice la GPU por defecto\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Especificar la GPU por defecto\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Manejar error\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "## Leer la data\n",
    "\n",
    "Primero, miremos el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:54.271601Z",
     "iopub.status.busy": "2023-11-16T12:28:54.271350Z",
     "iopub.status.idle": "2023-11-16T12:28:54.276974Z",
     "shell.execute_reply": "2023-11-16T12:28:54.276270Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(\"game_of_thrones.txt\", 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:54.280628Z",
     "iopub.status.busy": "2023-11-16T12:28:54.279970Z",
     "iopub.status.idle": "2023-11-16T12:28:54.283601Z",
     "shell.execute_reply": "2023-11-16T12:28:54.282992Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:54.286599Z",
     "iopub.status.busy": "2023-11-16T12:28:54.286362Z",
     "iopub.status.idle": "2023-11-16T12:28:54.303027Z",
     "shell.execute_reply": "2023-11-16T12:28:54.302388Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Vectorizacion del texto\n",
    "\n",
    "Previo al entrenamiento, necesitamos convertir el texto a una representacion numerica. \n",
    "\n",
    "La capa `tf.keras.layers.StringLookup` nos permite convertir cada caracter en un ID numerico. Solo necesita que el texto este separado primero en tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:54.305984Z",
     "iopub.status.busy": "2023-11-16T12:28:54.305759Z",
     "iopub.status.idle": "2023-11-16T12:28:56.476391Z",
     "shell.execute_reply": "2023-11-16T12:28:56.475487Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s4f1q3iqY8f"
   },
   "source": [
    "Ahora creamos la capa `tf.keras.layers.StringLookup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.479758Z",
     "iopub.status.busy": "2023-11-16T12:28:56.479480Z",
     "iopub.status.idle": "2023-11-16T12:28:56.500032Z",
     "shell.execute_reply": "2023-11-16T12:28:56.499180Z"
    },
    "id": "6GMlCe3qzaL9"
   },
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmX_jbgQqfOi"
   },
   "source": [
    "Esto nos convierte de tokens a IDs de caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.503579Z",
     "iopub.status.busy": "2023-11-16T12:28:56.503326Z",
     "iopub.status.idle": "2023-11-16T12:28:56.512120Z",
     "shell.execute_reply": "2023-11-16T12:28:56.511277Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "Dado que el proposito de este laboratorio es generar texto, tambien sera importante invertir esta representacion y recuperar texto legible desde estos IDs. Para esto podemos usar `tf.keras.layers.StringLookup(..., invert=True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uenivzwqsDhp"
   },
   "source": [
    "Nota: Aquí, en lugar de pasar el vocabulario original generado con `sorted(set(text))`, usamos el método `get_vocabulary()` de la capa `tf.keras.layers.StringLookup` para que los tokens `[UNK]` se configuren de la misma manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.515523Z",
     "iopub.status.busy": "2023-11-16T12:28:56.515247Z",
     "iopub.status.idle": "2023-11-16T12:28:56.527399Z",
     "shell.execute_reply": "2023-11-16T12:28:56.526413Z"
    },
    "id": "Wd2m3mqkDjRj"
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqTDDxS-s-H8"
   },
   "source": [
    "Esta capa recupera los caracteres desde los vectores de IDs y los retorna como un `tf.RaggedTensor` de caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.530933Z",
     "iopub.status.busy": "2023-11-16T12:28:56.530668Z",
     "iopub.status.idle": "2023-11-16T12:28:56.537090Z",
     "shell.execute_reply": "2023-11-16T12:28:56.536263Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FeW5gqutT3o"
   },
   "source": [
    "Finalmente usando `tf.strings.reduce_join` se pueden volver a juntar los caracteres en texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.540726Z",
     "iopub.status.busy": "2023-11-16T12:28:56.540204Z",
     "iopub.status.idle": "2023-11-16T12:28:56.612264Z",
     "shell.execute_reply": "2023-11-16T12:28:56.611386Z"
    },
    "id": "zxYI-PeltqKP"
   },
   "outputs": [],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.615892Z",
     "iopub.status.busy": "2023-11-16T12:28:56.615233Z",
     "iopub.status.idle": "2023-11-16T12:28:56.619392Z",
     "shell.execute_reply": "2023-11-16T12:28:56.618581Z"
    },
    "id": "w5apvBDn9Ind"
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### Prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "Dado un caracter, o una secuencia de caracteres, ¿cuál es el siguiente caracter más probable? Esta es la tarea para la que estamos entrenando al modelo. La entrada al modelo será una secuencia de caracteres y entrenamos el modelo para predecir la salida: el siguiente carácter en cada paso de tiempo.\n",
    "\n",
    "Dado que los RNN mantienen un estado interno que depende de los elementos vistos anteriormente, a partir de todos los caracteres calculados hasta este momento, ¿cuál es el siguiente carácter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Crear los ejemplos de entrenamiento\n",
    "\n",
    "Dividimos el texto en secuencias de ejemplo. Cada secuencia de entrada contendrá `seq_length` caracteres del texto.\n",
    "\n",
    "Para cada secuencia de entrada, los targets correspondientes contienen la misma longitud de texto, excepto que se desplazan un carácter hacia la derecha.\n",
    "\n",
    "Así que divida el texto en fragmentos de `seq_length+1`. Por ejemplo, digamos que `seq_length` es 3 y nuestro texto es \"Hola\". La secuencia de entrada sería \"Hol\" y la secuencia target \"ola\".\n",
    "\n",
    "Para hacer esto, usamos la función `tf.data.Dataset.from_tensor_slices` para convertir el vector de texto en una secuencia de índices de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:56.622927Z",
     "iopub.status.busy": "2023-11-16T12:28:56.622442Z",
     "iopub.status.idle": "2023-11-16T12:28:57.016742Z",
     "shell.execute_reply": "2023-11-16T12:28:57.015824Z"
    },
    "id": "UopbsKi88tm5"
   },
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.020447Z",
     "iopub.status.busy": "2023-11-16T12:28:57.019715Z",
     "iopub.status.idle": "2023-11-16T12:28:57.025333Z",
     "shell.execute_reply": "2023-11-16T12:28:57.024427Z"
    },
    "id": "qmxrYDCTy-eL"
   },
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.028784Z",
     "iopub.status.busy": "2023-11-16T12:28:57.028159Z",
     "iopub.status.idle": "2023-11-16T12:28:57.054262Z",
     "shell.execute_reply": "2023-11-16T12:28:57.053600Z"
    },
    "id": "cjH5v45-yqqH"
   },
   "outputs": [],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.057537Z",
     "iopub.status.busy": "2023-11-16T12:28:57.057035Z",
     "iopub.status.idle": "2023-11-16T12:28:57.060268Z",
     "shell.execute_reply": "2023-11-16T12:28:57.059485Z"
    },
    "id": "C-G2oaTxy6km"
   },
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "El método `batch` nos permite convertir fácilmente estos caracteres individuales en secuencias del tamaño deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.063362Z",
     "iopub.status.busy": "2023-11-16T12:28:57.063138Z",
     "iopub.status.idle": "2023-11-16T12:28:57.079344Z",
     "shell.execute_reply": "2023-11-16T12:28:57.078694Z"
    },
    "id": "BpdjRO2CzOfZ"
   },
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PHW902-4oZt"
   },
   "source": [
    "Es mas facil ver lo que esta haciendo si unimos de vuelta los tokens en texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.082545Z",
     "iopub.status.busy": "2023-11-16T12:28:57.082097Z",
     "iopub.status.idle": "2023-11-16T12:28:57.097362Z",
     "shell.execute_reply": "2023-11-16T12:28:57.096684Z"
    },
    "id": "QO32cMWu4a06"
   },
   "outputs": [],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "Para el entrenamiento, necesitaremos un conjunto de datos de pares `(input, label)`. Donde `input` y\n",
    "`label` son secuencias. En cada timestep, la entrada es el carácter actual y la etiqueta es el siguiente carácter.\n",
    "\n",
    "Aquí hay una función que toma una secuencia como entrada, la duplica y la desplaza para alinear la entrada y la etiqueta para cada timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.100570Z",
     "iopub.status.busy": "2023-11-16T12:28:57.099992Z",
     "iopub.status.idle": "2023-11-16T12:28:57.103529Z",
     "shell.execute_reply": "2023-11-16T12:28:57.102915Z"
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.106445Z",
     "iopub.status.busy": "2023-11-16T12:28:57.106212Z",
     "iopub.status.idle": "2023-11-16T12:28:57.110783Z",
     "shell.execute_reply": "2023-11-16T12:28:57.110161Z"
    },
    "id": "WxbDTJTw5u_P"
   },
   "outputs": [],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.113994Z",
     "iopub.status.busy": "2023-11-16T12:28:57.113409Z",
     "iopub.status.idle": "2023-11-16T12:28:57.150308Z",
     "shell.execute_reply": "2023-11-16T12:28:57.149691Z"
    },
    "id": "B9iKPXkw5xwa"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.153244Z",
     "iopub.status.busy": "2023-11-16T12:28:57.153010Z",
     "iopub.status.idle": "2023-11-16T12:28:57.182838Z",
     "shell.execute_reply": "2023-11-16T12:28:57.182219Z"
    },
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Batches de entrenamiento\n",
    "\n",
    "Usamos `tf.data` para dividir el texto en secuencias manejables. Pero antes de introducir estos datos en el modelo, es necesario mezclarlos y batchearlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.186368Z",
     "iopub.status.busy": "2023-11-16T12:28:57.185700Z",
     "iopub.status.idle": "2023-11-16T12:28:57.196417Z",
     "shell.execute_reply": "2023-11-16T12:28:57.195811Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Construccion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "En esta sección definimos el modelo como una subclase de `keras.Model` (para obtener más detalles, consulte [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)).\n",
    "\n",
    "Este modelo tiene tres capas:\n",
    "\n",
    "* `tf.keras.layers.Embedding`: La capa de entrada. Una lookup table entrenable que asignará cada ID de carácter a un vector con dimensiones `embedding_dim`;\n",
    "* `tf.keras.layers.GRU`: una capa recurrente GRU de tamaño `units=rnn_units` (también se puede usar una capa LSTM aquí).\n",
    "* `tf.keras.layers.Dense`: La capa de salida, con salidas `vocab_size`. Genera un logit para cada carácter del vocabulario. Estas son las probabilidades de cada caracter según el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.199659Z",
     "iopub.status.busy": "2023-11-16T12:28:57.199433Z",
     "iopub.status.idle": "2023-11-16T12:28:57.203643Z",
     "shell.execute_reply": "2023-11-16T12:28:57.203074Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.206868Z",
     "iopub.status.busy": "2023-11-16T12:28:57.206479Z",
     "iopub.status.idle": "2023-11-16T12:28:57.212069Z",
     "shell.execute_reply": "2023-11-16T12:28:57.211498Z"
    },
    "id": "wj8HQ2w8z4iO"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.215201Z",
     "iopub.status.busy": "2023-11-16T12:28:57.214660Z",
     "iopub.status.idle": "2023-11-16T12:28:57.230058Z",
     "shell.execute_reply": "2023-11-16T12:28:57.229421Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "Por cada caracter el modelo calcula su embedding, corre la GRU un timestep con el embedding como entrada y aplica la capa densa para generar los logits prediciendo la probabilidades del siguiente caracter.\n",
    "\n",
    "![A drawing of the data passing through the model](images/text_generation_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKbfm04amhXk"
   },
   "source": [
    "Nota: Para el entrenamiento, se puede utilizar un modelo `keras.Sequential`. Para generar texto más adelante, necesitaremos administrar el estado interno de la RNN. Es más sencillo incluir las opciones de entrada y salida de estado por adelantado que reorganizar la arquitectura del modelo más adelante. Para obtener más detalles, consulte [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Probar el modelo\n",
    "\n",
    "Ejecutamos el modelo para ver que se comporta como se esperaba.\n",
    "\n",
    "Primero verificamos la shape de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:57.233847Z",
     "iopub.status.busy": "2023-11-16T12:28:57.233365Z",
     "iopub.status.idle": "2023-11-16T12:28:59.298091Z",
     "shell.execute_reply": "2023-11-16T12:28:59.297223Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "En el ejemplo anterior, la longitud de la secuencia de la entrada es `100`, pero el modelo se puede ejecutar con entradas de cualquier longitud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.301864Z",
     "iopub.status.busy": "2023-11-16T12:28:59.301192Z",
     "iopub.status.idle": "2023-11-16T12:28:59.313047Z",
     "shell.execute_reply": "2023-11-16T12:28:59.312318Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "Para obtener predicciones reales del modelo, se deben tomar muestras de la distribución de salida para obtener índices de caracteres reales. Esta distribución está definida por los logits sobre el vocabulario de los caracteres.\n",
    "\n",
    "Nota: Es importante tomar una muestra de esta distribución, ya que tomar el _argmax_ de la distribución puede fácilmente hacer que el modelo se atasque en un bucle.\n",
    "\n",
    "Tomando como ejemplo el primero del batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.320016Z",
     "iopub.status.busy": "2023-11-16T12:28:59.319623Z",
     "iopub.status.idle": "2023-11-16T12:28:59.326563Z",
     "shell.execute_reply": "2023-11-16T12:28:59.325985Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "Esto nos da para cada timestep una predicción del siguiente índice de caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.330052Z",
     "iopub.status.busy": "2023-11-16T12:28:59.329445Z",
     "iopub.status.idle": "2023-11-16T12:28:59.333889Z",
     "shell.execute_reply": "2023-11-16T12:28:59.333297Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "Por ultimo los decodificamos para ver el texto predicho por este modelo no entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.337383Z",
     "iopub.status.busy": "2023-11-16T12:28:59.336856Z",
     "iopub.status.idle": "2023-11-16T12:28:59.343044Z",
     "shell.execute_reply": "2023-11-16T12:28:59.342429Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "El problema puede tratarse como un problema de clasificación estándar. Dado el estado RNN anterior y la entrada en este timestep, predice la clase del siguiente carácter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### Agregamos un optimizador y una funcion costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "La función de pérdida estándar `tf.keras.losses.sparse_categorical_crossentropy` funciona en este caso porque se aplica en la última dimensión de las predicciones.\n",
    "\n",
    "Debido a que su modelo devuelve logits, necesita configurar el indicador `from_logits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.346468Z",
     "iopub.status.busy": "2023-11-16T12:28:59.346077Z",
     "iopub.status.idle": "2023-11-16T12:28:59.349273Z",
     "shell.execute_reply": "2023-11-16T12:28:59.348679Z"
    },
    "id": "ZOeWdgxNFDXq"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.352397Z",
     "iopub.status.busy": "2023-11-16T12:28:59.351903Z",
     "iopub.status.idle": "2023-11-16T12:28:59.372218Z",
     "shell.execute_reply": "2023-11-16T12:28:59.371637Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkvUIneTFiow"
   },
   "source": [
    "Un modelo recién inicializado no debería estar demasiado seguro de sí mismo, todos los logits de salida deberían tener magnitudes similares. Para confirmar esto, puede comprobar que la exponencial del costo medio es aproximadamente igual al tamaño del vocabulario. Una pérdida mucho mayor significa que el modelo está seguro de sus respuestas incorrectas y está mal inicializado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.375456Z",
     "iopub.status.busy": "2023-11-16T12:28:59.375183Z",
     "iopub.status.idle": "2023-11-16T12:28:59.468894Z",
     "shell.execute_reply": "2023-11-16T12:28:59.468146Z"
    },
    "id": "MAJfS5YoFiHf"
   },
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "Compilamos el modelo con `tf.keras.Model.compile` indicando el optimizador y la funcion costo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.472229Z",
     "iopub.status.busy": "2023-11-16T12:28:59.471982Z",
     "iopub.status.idle": "2023-11-16T12:28:59.487518Z",
     "shell.execute_reply": "2023-11-16T12:28:59.486923Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Checkpoints del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6XBUUavgF56"
   },
   "source": [
    "Usamos el callback `tf.keras.callbacks.ModelCheckpoint` para que se guarden checkpoints del modelo durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.491101Z",
     "iopub.status.busy": "2023-11-16T12:28:59.490600Z",
     "iopub.status.idle": "2023-11-16T12:28:59.494365Z",
     "shell.execute_reply": "2023-11-16T12:28:59.493792Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Ejecucion del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "Para mantener un tiempo de entrenamiento razonable, utilice entre 10 y 20 épocas para entrenar el modelo. En Colab, configure el tiempo de ejecución en GPU para un entrenamiento más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.497610Z",
     "iopub.status.busy": "2023-11-16T12:28:59.497078Z",
     "iopub.status.idle": "2023-11-16T12:28:59.499950Z",
     "shell.execute_reply": "2023-11-16T12:28:59.499383Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:28:59.503111Z",
     "iopub.status.busy": "2023-11-16T12:28:59.502603Z",
     "iopub.status.idle": "2023-11-16T12:32:44.620282Z",
     "shell.execute_reply": "2023-11-16T12:32:44.619503Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generacion de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIdQ8c8NvMzV"
   },
   "source": [
    "La forma más sencilla de generar texto con este modelo es ejecutarlo en un bucle y realizar un seguimiento del estado interno del modelo a medida que lo ejecutamos.\n",
    "\n",
    "![Para generar texto, la salida del modelo se retroalimenta a la entrada](images/text_generation_sampling.png)\n",
    "\n",
    "Cada vez que llamamos al modelo, pasamos algún texto y un estado interno. El modelo devuelve una predicción para el siguiente caracter y su nuevo estado. Vuelva a pasar la predicción y el estado para continuar generando texto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "Lo siguiente hace una predicción de un solo paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:32:44.624308Z",
     "iopub.status.busy": "2023-11-16T12:32:44.624035Z",
     "iopub.status.idle": "2023-11-16T12:32:44.632095Z",
     "shell.execute_reply": "2023-11-16T12:32:44.631505Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:32:44.635387Z",
     "iopub.status.busy": "2023-11-16T12:32:44.634915Z",
     "iopub.status.idle": "2023-11-16T12:32:44.650442Z",
     "shell.execute_reply": "2023-11-16T12:32:44.649807Z"
    },
    "id": "fqMOuDutnOxK"
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9yDoa0G3IgQ"
   },
   "source": [
    "Lo ejecutamos en un bucle para generar texto. Al observar el texto generado, veremos que el modelo sabe cuándo poner mayúsculas, hacer párrafos e imita un vocabulario de escritura similar al de Game Of Thrones. Con el reducido número de épocas de entrenamiento, todavía no ha aprendido a formar frases coherentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:32:44.653513Z",
     "iopub.status.busy": "2023-11-16T12:32:44.653276Z",
     "iopub.status.idle": "2023-11-16T12:32:47.538437Z",
     "shell.execute_reply": "2023-11-16T12:32:47.537704Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['The Targaryens'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "Lo más fácil que podemos hacer para mejorar los resultados es entrenarlo por más tiempo (prueba con `EPOCHS = 30`).\n",
    "\n",
    "También puede experimentar con una secuencia de inicio diferente, intentar agregar otra capa RNN para mejorar la precisión del modelo o ajustar el parámetro de temperatura para generar predicciones más o menos aleatorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OfbI4aULmuj"
   },
   "source": [
    "Si queremos que el modelo genere texto *más rápido*, lo más fácil que se puede hacer es generar el texto por batches. En el siguiente ejemplo, el modelo genera 5 resultados aproximadamente en el mismo tiempo que tomó generar 1 arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T12:32:47.542226Z",
     "iopub.status.busy": "2023-11-16T12:32:47.541967Z",
     "iopub.status.idle": "2023-11-16T12:32:50.432850Z",
     "shell.execute_reply": "2023-11-16T12:32:50.432024Z"
    },
    "id": "ZkLu7Y8UCMT7"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['The Targaryens', 'The Targaryens', 'The Targaryens', 'The Targaryens', 'The Targaryens'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
